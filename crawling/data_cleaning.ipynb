{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e912de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder if it doesn't exist\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ff840",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = []  # Collect logs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cffaaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV\n",
    "papers_df = pd.read_csv(\"./output/papers.csv\")\n",
    "log.append(f\"Initial shape: {papers_df.shape[0]} rows, {papers_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271449f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove exact duplicate rows\n",
    "duplicate_rows = papers_df.duplicated()\n",
    "log.append(f\"Total exact duplicate rows: {duplicate_rows.sum()}\")\n",
    "papers_df = papers_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Check and remove duplicates by key columns\n",
    "for col in ['Title']:\n",
    "    if col in papers_df.columns:\n",
    "        count = papers_df.duplicated(subset=col, keep=False).sum()\n",
    "        log.append(f\"- Duplicate entries in \\\"{col}\\\": {count}\")\n",
    "        papers_df = papers_df.drop_duplicates(subset=col, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90336ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Check for missing (NaN) values\n",
    "na_counts = papers_df.isna().sum()\n",
    "log.append(\"Missing (NaN) values per column:\")\n",
    "log.extend([f\"  - {col}: {na_counts[col]}\" for col in na_counts.index if na_counts[col] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e33c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Check for empty strings\n",
    "empty_counts = (papers_df == '').sum()\n",
    "log.append(\"Empty string entries per column:\")\n",
    "log.extend([f\"  - {col}: {empty_counts[col]}\" for col in empty_counts.index if empty_counts[col] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9302ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Check for any rows that are partially empty\n",
    "partially_empty = papers_df.isna().any(axis=1) | (papers_df == '').any(axis=1)\n",
    "log.append(f\"Rows with any missing (NaN) or empty strings: {partially_empty.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41082cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final shape\n",
    "log.append(f\"Final shape after cleaning: {papers_df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76944c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned file\n",
    "cleaned_path = os.path.join(output_dir, \"papers_cleaned.csv\")\n",
    "papers_df.to_csv(cleaned_path, index=False)\n",
    "log.append(f\"Cleaned data saved to '{cleaned_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d228ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save log\n",
    "log_path = os.path.join(output_dir, \"cleaning_log.txt\")\n",
    "with open(log_path, \"w\", encoding='utf-8') as f:\n",
    "    for line in log:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d452fd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"Cleaning complete. Outputs written to '{output_dir}' folder.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
